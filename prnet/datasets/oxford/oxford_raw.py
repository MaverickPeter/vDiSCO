# Functions and classes operating on a raw Oxford dataset

import numpy as np
import cv2
import os
from typing import List
from torch.utils.data import Dataset, ConcatDataset
from sklearn.neighbors import KDTree
import torch
import random
import struct
import math
from prnet.datasets.oxford.utils import read_lidar_poses, in_test_split, in_train_split, find_nearest_ndx, read_ts_file
from prnet.datasets.oxford import velodyne
from prnet.utils.data_utils.point_clouds import PointCloudLoader, PointCloudWithImageLoader
from prnet.utils.common_utils import ssc_to_homo
import matplotlib.pyplot as plt
import pickle
import copy
import re
from PIL import Image
from colour_demosaicing import demosaicing_CFA_Bayer_bilinear as demosaic
import numpy as np
from mpl_toolkits.mplot3d import Axes3D
import matplotlib.pyplot as plt

BAYER_STEREO = 'gbrg'
BAYER_MONO = 'rggb'


# concantate pointclouds generated by the left and right lidar
def pc_concantate(pc_left, pc_right, extrinsics_dir):
    '''velodyne'''
    left = np.loadtxt(os.path.join(extrinsics_dir, 'velodyne_left.txt'), delimiter=' ', dtype=np.float64)
    roll, pitch, yaw = left[3], left[4], left[5]
    # convert euler angles to rotation matrix
    left_T =np.eye(4)
    R_x = np.array([[1, 0, 0],
                    [0, np.cos(roll), -np.sin(roll)],
                    [0, np.sin(roll), np.cos(roll)]])
    R_y = np.array([[np.cos(pitch), 0, np.sin(pitch)],
                    [0, 1, 0],
                    [-np.sin(pitch), 0, np.cos(pitch)]])
    R_z = np.array([[np.cos(yaw), -np.sin(yaw), 0],
                    [np.sin(yaw), np.cos(yaw), 0],
                    [0, 0, 1]])
    R = np.dot(R_z, np.dot(R_y, R_x))
    # translation
    t = np.array(left[:3])
    left_T[:3, :3] = R
    left_T[:3, 3] = t
    intensity_array = copy.deepcopy(pc_left[3,:])
    pc_left[3,:] = 1
    pc_left_ed = np.dot(left_T, pc_left)  
    pc_left[3,:] = intensity_array
    pc_left_ed[3,:] = intensity_array
    
    right= np.loadtxt(os.path.join(extrinsics_dir, 'velodyne_right.txt'), delimiter=' ', dtype=np.float64)
    roll, pitch, yaw = right[3], right[4], right[5]
    # convert euler angles to rotation matrix
    right_T =np.eye(4)
    R_x = np.array([[1, 0, 0],
                    [0, np.cos(roll), -np.sin(roll)],
                    [0, np.sin(roll), np.cos(roll)]])
    R_y = np.array([[np.cos(pitch), 0, np.sin(pitch)],
                    [0, 1, 0],
                    [-np.sin(pitch), 0, np.cos(pitch)]])
    R_z = np.array([[np.cos(yaw), -np.sin(yaw), 0],
                    [np.sin(yaw), np.cos(yaw), 0],
                    [0, 0, 1]])
    R = np.dot(R_z, np.dot(R_y, R_x))
    # translation
    t = np.array(right[:3])
    right_T[:3, :3] = R
    right_T[:3, 3] = t
    intensity_array = copy.deepcopy(pc_right[3,:])
    pc_right[3,:] = 1
    pc_right_ed = np.dot(right_T, pc_right)  
    pc_right[3,:] = intensity_array
    pc_right_ed[3,:] = intensity_array
    pc_cat = np.concatenate((pc_left_ed, pc_right_ed), axis=1)
    pc_cat = pc_cat.transpose()

    return pc_cat
    

# load lidar file in oxford radar robotcar dataset
def load_lidar_file_oxford_radar(file_path):
    n_vec = 4
    # ranges, intensities, angles, approximate_timestamps = velodyne.load_velodyne_raw(file_path)
    # lidar_pc_raw = velodyne.velodyne_raw_to_pointcloud(ranges, intensities, angles)
    # lidar_pc_raw = lidar_pc_raw.reshape((-1, n_vec))
    lidar_pc_raw = velodyne.load_velodyne_binary(file_path)
    # lidar_pc_raw = lidar_pc_raw.transpose(1, 0)
    
    return lidar_pc_raw


def load_img_file_oxford(filename, cam_mode):
    input_image = cv2.imread(filename)
    input_image = cv2.cvtColor(input_image, cv2.COLOR_BGR2RGB)
    return input_image


class OxfordPointCloudWithImageLoader(PointCloudWithImageLoader):
    def set_properties(self):
        # Set point cloud properties, such as ground_plane_level.
        self.ground_plane_level = 2.0
        self.remove_ground_plane = False

    def read_pcim(self, file_pathname: list, sph=False, extrinsics_dir=None) -> torch.Tensor:
        # Reads the point cloud without pre-processing
        # Returns Nx4 tensor

        assert extrinsics_dir is not None, 'need extrinsics_dir param for oxford dataset'

        left_velo_filename = file_pathname[0]
        right_velo_filename = file_pathname[1]

        pc_left = load_lidar_file_oxford_radar(left_velo_filename)
        pc_right = load_lidar_file_oxford_radar(right_velo_filename)
        pc = pc_concantate(pc_left, pc_right, extrinsics_dir)

        mask = (np.abs(pc[:,0]) < 70.) * (pc[:,2] > -28) * (pc[:,2] < self.ground_plane_level) \
            * (np.abs(pc[:,1]) < 70) * (np.linalg.norm(pc[:,:2]) > 2.)

        # pc = pc[idx,:]
        # mask = pc[:, 2] < self.ground_plane_level
        pc = pc[mask]

        camera_mode = ["mono_left", "mono_right", "mono_rear", "stereo"]
        if sph:
            images = [load_img_file_oxford(file_pathname[2].replace('mono_left_rect', 'sph'), camera_mode[0])]
        else:
            images = [load_img_file_oxford(file_pathname[i], camera_mode[i-2]) for i in range(2, 6)]

        return pc, images


class OxfordPointCloudLoader(PointCloudLoader):
    def set_properties(self):
        # Set point cloud properties, such as ground_plane_level.
        self.ground_plane_level = 2.0

    def read_pc(self, file_pathname: list, extrinsics_dir=None) -> torch.Tensor:
        # Reads the point cloud without pre-processing
        # Returns Nx3 tensor
        assert extrinsics_dir is not None, 'need extrinsics_dir param for oxford dataset'

        left_velo_filename = file_pathname[0]
        right_velo_filename = file_pathname[1]

        pc_left = load_lidar_file_oxford_radar(left_velo_filename)
        pc_right = load_lidar_file_oxford_radar(right_velo_filename)
        pc = pc_concantate(pc_left, pc_right, extrinsics_dir)

        mask = (np.abs(pc[:,0]) < 70.) * (pc[:,2] > -28) * (pc[:,2] < self.ground_plane_level) \
            * (np.abs(pc[:,1]) < 70) * (np.linalg.norm(pc[:,:2]) > 2.)
        pc = pc[mask]

        imgs = None
        return pc, imgs


class OxfordSequence(Dataset):
    """
    Dataset returns a point cloud from a train or test split from one sequence from a raw Mulran dataset
    """
    def __init__(self, dataset_root: str, sequence_name: str, split: str, sampling_distance: float = 0.2):
        assert os.path.exists(dataset_root), f'Cannot access dataset root: {dataset_root}'
        assert split in ['train', 'test', 'all']

        self.dataset_root = dataset_root
        self.sequence_name = sequence_name
        sequence_path = os.path.join(self.dataset_root, self.sequence_name)
        assert os.path.exists(sequence_path), f'Cannot access sequence: {sequence_path}'

        self.right_lidar_tsfile = os.path.join(sequence_path, 'velodyne_right.timestamps')
        self.mono_left_tsfile = os.path.join(sequence_path, 'mono_left.timestamps')
        self.mono_right_tsfile = os.path.join(sequence_path, 'mono_right.timestamps')
        self.mono_rear_tsfile = os.path.join(sequence_path, 'mono_rear.timestamps')
        self.stereo_tsfile = os.path.join(sequence_path, 'stereo.timestamps')

        self.right_lidar_ts = read_ts_file(self.right_lidar_tsfile)    
        self.mono_left_ts = read_ts_file(self.mono_left_tsfile)
        self.mono_right_ts = read_ts_file(self.mono_right_tsfile)
        self.mono_rear_ts = read_ts_file(self.mono_rear_tsfile)
        self.stereo_ts = read_ts_file(self.stereo_tsfile)    


        self.split = split
        self.sampling_distance = sampling_distance
        
        # Maximum discrepancy between timestamps of LiDAR scan and global pose in seconds
        self.pose_time_tolerance = 1.

  
        self.pose_file = os.path.join(sequence_path, 'gps/ins.csv')
        assert os.path.exists(self.pose_file), f'Cannot access ground truth file: {self.pose_file}'

        self.rel_left_lidar_path = os.path.join(self.sequence_name, 'velodyne_left')
        left_lidar_path = os.path.join(self.dataset_root, self.rel_left_lidar_path)
        assert os.path.exists(left_lidar_path), f'Cannot access left lidar scans: {left_lidar_path}'

        self.pcim_loader = OxfordPointCloudWithImageLoader()

        timestamps, poses = read_lidar_poses(self.pose_file, left_lidar_path, self.pose_time_tolerance)
        self.xys = poses[:, :2, 3]
        self.timestamps, self.poses = self.filter(timestamps, poses)

        self.rel_scan_filepath = [os.path.join(self.rel_left_lidar_path, str(e) + '.bin') for e in self.timestamps]

        self.extrinsics_dir = os.path.join(self.dataset_root, 'extrinsics')
        filepaths = []
        for idx in range(len(self.rel_scan_filepath)):
            filepaths.append(self.get_filepaths(idx))
        self.filepaths = filepaths

        assert len(self.timestamps) == len(self.poses)
        assert len(self.timestamps) == len(self.rel_scan_filepath)
        print(f'{len(self.timestamps)} scans in {sequence_name}-{split}')

    def __len__(self):
        return len(self.rel_scan_filepath)

    def __getitem__(self, ndx):
        filepaths = self.get_filepaths(ndx)
        pcs, images = self.pcim_loader(filepaths, extrinsics_dir=self.extrinsics_dir)

        return {'pc': pcs, 'img': images, 'pose': self.poses[ndx], 'ts': self.timestamps[ndx],
                'position': self.poses[ndx][:2, 3]}


    def get_filepaths(self, ndx):
        reading_left_lidar_filepath = os.path.join(self.dataset_root, self.rel_scan_filepath[ndx])
        timestamps = self.timestamps[ndx]

        right_lidar_ndx = find_nearest_ndx(timestamps, self.right_lidar_ts)
        mono_left_ndx = find_nearest_ndx(timestamps, self.mono_left_ts)
        mono_right_ndx = find_nearest_ndx(timestamps, self.mono_right_ts)
        mono_rear_ndx = find_nearest_ndx(timestamps, self.mono_rear_ts)
        stereo_ndx = find_nearest_ndx(timestamps, self.stereo_ts)

        right_lidar_timestamp = self.right_lidar_ts[right_lidar_ndx]
        mono_left_timestamp = self.mono_left_ts[mono_left_ndx]
        mono_right_timestamp = self.mono_right_ts[mono_right_ndx]
        mono_rear_timestamp = self.mono_rear_ts[mono_rear_ndx]
        stereo_timestamp = self.stereo_ts[stereo_ndx]

        reading_right_lidar_filepath = reading_left_lidar_filepath.replace("velodyne_left", "velodyne_right")
        reading_mono_left_filepath = reading_left_lidar_filepath.replace("velodyne_left", "mono_left_rect")
        reading_mono_right_filepath = reading_left_lidar_filepath.replace("velodyne_left", "mono_right_rect")
        reading_mono_rear_filepath = reading_left_lidar_filepath.replace("velodyne_left", "mono_rear_rect")
        reading_stereo_filepath = reading_left_lidar_filepath.replace("velodyne_left", "stereo/centre_rect")

        reading_mono_left_filepath = reading_mono_left_filepath.replace("bin", "png")
        reading_mono_right_filepath = reading_mono_right_filepath.replace("bin", "png")
        reading_mono_rear_filepath = reading_mono_rear_filepath.replace("bin", "png")
        reading_stereo_filepath = reading_stereo_filepath.replace("bin", "png")

        reading_right_lidar_filepath = reading_right_lidar_filepath.replace(str(timestamps), str(right_lidar_timestamp))
        reading_mono_left_filepath = reading_mono_left_filepath.replace(str(timestamps), str(mono_left_timestamp))
        reading_mono_right_filepath = reading_mono_right_filepath.replace(str(timestamps), str(mono_right_timestamp))
        reading_mono_rear_filepath = reading_mono_rear_filepath.replace(str(timestamps), str(mono_rear_timestamp))
        reading_stereo_filepath = reading_stereo_filepath.replace(str(timestamps), str(stereo_timestamp))

        filepaths = [reading_left_lidar_filepath, reading_right_lidar_filepath, reading_mono_left_filepath, reading_mono_right_filepath, reading_mono_rear_filepath, reading_stereo_filepath]

        return filepaths


    def load_pcs(self, scan_paths):
        # Load point cloud from file
        pcs = []
        for scan_path in scan_paths:
            pc = load_lidar_file_oxford(scan_path)
            if len(pc) == 0:
                continue
            pcs.append(pc)
        pcs = np.array(pcs)
        return pcs 
        

    def filter(self, ts: np.ndarray, poses: np.ndarray):
        # Filter out scans - retain only scans within a given split with minimum displacement
        positions = poses[:, :2, 3]

        # Retain elements in the given split
        # Only sejong sequence has train/test split
        if self.split != 'all':
            if self.split == 'train':
                mask = in_train_split(positions)
            elif self.split == 'test':
                mask = in_test_split(positions)

            ts = ts[mask]
            poses = poses[mask]
            positions = positions[mask]
            print(f'Split: {self.split}   Mask len: {len(mask)}   Mask True: {np.sum(mask)}')

        # Filter out scans - retain only scans within a given split
        prev_position = None
        mask = []
        for ndx, position in enumerate(positions):
            if prev_position is None:
                mask.append(ndx)
                prev_position = position
            else:
                displacement = np.linalg.norm(prev_position - position)
                # print("displacement: ", displacement)
                if displacement > self.sampling_distance:
                    mask.append(ndx)
                    prev_position = position

        ts = ts[mask]
        poses = poses[mask]
        
        return ts, poses


class OxfordSequences(Dataset):
    """
    Multiple Oxford sequences indexed as a single dataset. Each element is identified by a unique global index.
    """
    def __init__(self, dataset_root: str, sequence_names: List[str], split: str, sampling_distance: float = 1.0):
        assert len(sequence_names) > 0
        assert os.path.exists(dataset_root), f'Cannot access dataset root: {dataset_root}'
        assert split in ['train', 'test', 'all']

        self.dataset_root = dataset_root
        self.sequence_names = sequence_names
        self.split = split
        self.sampling_distance = sampling_distance

        sequences = []
        for seq_name in self.sequence_names:
            ds = OxfordSequence(self.dataset_root, seq_name, split=split, sampling_distance=sampling_distance)
            sequences.append(ds)

        self.dataset = ConcatDataset(sequences)

        # Concatenate positions from all sequences
        self.poses = np.zeros((len(self.dataset), 4, 4), dtype=np.float64)
        self.timestamps = np.zeros((len(self.dataset),), dtype=np.int64)
        self.rel_scan_filepath = []
        self.filepaths = []

        self.xys = self.poses[:, :2, 3]
        
        for cum_size, ds in zip(self.dataset.cumulative_sizes, sequences):
            # Consolidated lidar positions, timestamps and relative filepaths
            self.poses[cum_size - len(ds): cum_size, :] = ds.poses
            self.timestamps[cum_size - len(ds): cum_size] = ds.timestamps
            self.rel_scan_filepath.extend(ds.rel_scan_filepath)
            self.filepaths.extend(ds.filepaths)

        assert len(self.timestamps) == len(self.poses)
        assert len(self.timestamps) == len(self.rel_scan_filepath)

        # Build a kdtree based on X, Y position
        self.kdtree = KDTree(self.get_xy())

    def __len__(self):
        return len(self.dataset)

    def __getitem__(self, ndx):
        return self.dataset[ndx]

    def get_xy(self):
        # Get X, Y position from (4, 4) pose
        return self.poses[:, :2, 3]

    def load_pcs(self, scan_paths):
        # Load point cloud from file
        pcs = []
        for scan_path in scan_paths:
            pc = load_lidar_file_oxford(scan_path)
            if len(pc) == 0:
                continue
            pcs.append(pc)
        pcs = np.array(pcs)
        return pcs 

    def find_neighbours_ndx(self, position, radius):
        # Returns indices of neighbourhood point clouds for a given position
        assert position.ndim == 1
        assert position.shape[0] == 2
        # Reshape into (1, 2) axis
        position = position.reshape(1, -1)
        neighbours = self.kdtree.query_radius(position, radius)[0]
        random.shuffle(neighbours)

        return neighbours.astype(np.int32)


if __name__ == '__main__':
    dataset_root = '/mnt/workspace/datasets/Oxford/'
    sequence_names = ['2019-01-11-13-24-51-radar-oxford-10k']

    db = OxfordSequences(dataset_root, sequence_names, split='train')
    print(f'Number of scans in the sequence: {len(db)}')
    e = db[0]

    res = db.find_neighbours_ndx(e['position'], radius=50)
    print('.')



